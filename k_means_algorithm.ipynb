{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNW1EubEhTpGeSb9PshZKCf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polydeuces32/s-p500-predicter-on-Python-/blob/main/k_means_algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1_pg8kznMXB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1: Gather Data\n",
        "# Download historical data for S&P 500 stocks\n",
        "tickers = ['AAPL', 'LINK', 'BTC', 'AMZN', 'TSLA']  # Example tickers\n",
        "data = yf.download(tickers, start=\"2020-01-01\", end=\"2024-07-01\")\n",
        "\n",
        "# Calculate daily returns\n",
        "returns = data['Adj Close'].pct_change().dropna()\n",
        "\n",
        "# Step 2: Preprocess Data\n",
        "# Calculate annualized mean return and volatility\n",
        "mean_returns = returns.mean() * 252\n",
        "volatility = returns.std() * np.sqrt(252)\n",
        "\n",
        "# Create a DataFrame with the features\n",
        "features = pd.DataFrame({'Mean Returns': mean_returns, 'Volatility': volatility})\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "# Step 3: Apply k-means Clustering\n",
        "# Set number of clusters\n",
        "k = 3\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "kmeans.fit(scaled_features)\n",
        "\n",
        "# Assign clusters to the original data\n",
        "features['Cluster'] = kmeans.labels_\n",
        "\n",
        "# Step 4: Analyze and Interpret Results\n",
        "print(features)\n",
        "\n",
        "# Plot the clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Volatility', y='Mean Returns', hue='Cluster', data=features, palette='viridis')\n",
        "plt.title('K-means Clustering of S&P 500 Stocks')\n",
        "plt.xlabel('Volatility (Annualized)')\n",
        "plt.ylabel('Mean Returns (Annualized)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Step 1: Gather Data\n",
        "ticker = 'GBTC'\n",
        "data = yf.download(ticker, start=\"2010-01-01\", end=\"2025-01-01\")\n",
        "\n",
        "# Step 2: Preprocess Data\n",
        "# Using 'Close' price for prediction\n",
        "data = data[['Close']]\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# Create training and testing datasets\n",
        "train_size = int(len(scaled_data) * 0.8)\n",
        "train_data = scaled_data[:train_size]\n",
        "test_data = scaled_data[train_size:]\n",
        "\n",
        "# Create sequences for training\n",
        "def create_sequences(data, seq_length):\n",
        "    x, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        x.append(data[i:i + seq_length])\n",
        "        y.append(data[i + seq_length])\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "seq_length = 60  # Using 60 days of data to predict the next day's price\n",
        "x_train, y_train = create_sequences(train_data, seq_length)\n",
        "x_test, y_test = create_sequences(test_data, seq_length)\n",
        "\n",
        "# Step 3: Build LSTM Model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(seq_length, 1)))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=32)\n",
        "\n",
        "# Step 5: Make Predictions\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "# Compare with actual values\n",
        "actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Plot the results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(actual, color='blue', label='Actual Stock Price')\n",
        "plt.plot(predictions, color='red', label='Predicted Stock Price')\n",
        "plt.title('Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HdvuDCPkosfY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}